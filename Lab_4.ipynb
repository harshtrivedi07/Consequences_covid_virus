{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshtrivedi07/Consequences_covid_virus/blob/main/Lab_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VetI0thsAMjF"
      },
      "source": [
        "# Lab 4: Building an Image Classifier from Scratch\n",
        "\n",
        "The main goal of this lab is to create an image classifier from scratch using the Keras package. You will create a binary classifier based on an object type of your choice. The classifier will accept images and then predict whether or not a given image contains that object. For example, if you chose your object to be a cat, then the classifier would accept images and predict 1 if it believes there is a cat in the image or a 0 if not. \n",
        "\n",
        "You will build and train a classifier in two ways: \n",
        "- first using the original data set that you create, and \n",
        "- second, using data augmentation techniques. \n",
        "\n",
        "**Grading:** \n",
        "**Grading:** \n",
        "\n",
        " - 50% of the grade will come from FINAL, error-free code written in Python/Keras that accomplishes all the steps outlined in the instructions for each part of this lab and written in Python/Keras \n",
        " - 50% will come from descriptive comments associated with that code, where the comments explain what the code is doing and why it is important to the overall objective. Thus, comments like \"split the data\" or \"train the model\" would receive a grade of 0 as they do not indicate any understanding.\n",
        "\n",
        "**Research Required:** \n",
        "\n",
        "To complete this lab successfully you will need to do some research. At the very least, you will need to implement the [`ImageDataGenerator` class](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator) and the [`.flow_from_directory` method](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator#flow_from_directory). \n",
        "\n",
        "**What to submit:**\n",
        "- A copy of this notebook with:\n",
        "    - Error-free code in Python/Keras\n",
        "    - All code cells executed and output visible\n",
        "- Include a zipped file of your images\n",
        "\n",
        "\n",
        "\n",
        "## Part 1: Prep Work\n",
        "### Choose an Object\n",
        "\n",
        "**You may choose any object other than a cat**.\n",
        "\n",
        "### Create a Dataset\n",
        "Use the code provided below to:\n",
        " - download a minimum of 500 **useable** images of the chosen object\n",
        " - download a minimum of 500 **useable** images of other things that are not your object; there should be **at least 10 different types of objects** in this group of images\n",
        " \n",
        "You should manually verify that the images are indeed of the correct object; that is, sometimes the code will download images that are not of the desired search term and should be deleted. \n",
        " \n",
        "From these images you will create a training folder (minimum of 350 object/350 not object), a validation folder (minimum of 50 object/50 not object), and a test folder (minimum of 100 object/100 not object). The final counts should approximately represent a 70%/10%/20% split. **Code to create the training, validation, and test folders should be included.**\n",
        "\n",
        "It's best if your dataset is diverse, so verify that the images of the chosen object have, for example, different lighting, are from different angles, different distances from camera. Similarly for the *not object* images: try to include a variety of objects in different ways. \n",
        "\n",
        "**The images downloaded should not be used for any purpose other than personal academic use unless noted otherwise by the copyright holder of the image.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rxKCFoYAMjO"
      },
      "source": [
        "#### Code for image download\n",
        "\n",
        "Use the code cells below to download the required images. Note that you will most likely need to request more images than the required amount as some images will not be useable. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7mQyZUZQAMjP"
      },
      "outputs": [],
      "source": [
        "# modified version of code at https://python.plainenglish.io/how-to-automatically-download-bulk-images-for-your-dataset-using-python-f1efffba7a03\n",
        "import os\n",
        "import requests\n",
        "import pathlib\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-DLE4e7SAMjR"
      },
      "outputs": [],
      "source": [
        "google_image = \"https://www.google.com/search?site=&tbm=isch&source=hp&biw=1873&bih=990&\"\n",
        "\n",
        "user_agent = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkGrE2mlAMjS"
      },
      "outputs": [],
      "source": [
        "def download_images():\n",
        "    data = input('What are you looking for? ')\n",
        "    n_images = int(input('How many images do you want? '))\n",
        "\n",
        "    print(f'\\nSearching for {n_images}...\\n')\n",
        "\n",
        "    search_url = google_image + 'q=' + data\n",
        "\n",
        "    response = requests.get(search_url, headers=user_agent)\n",
        "    html = response.text\n",
        "\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "    results = soup.findAll('img', {'class': 'rg_i Q4LuWd'})\n",
        "\n",
        "    count = 1\n",
        "    links = []\n",
        "    \n",
        "    for result in results:\n",
        "        try:\n",
        "            link = result['data-src']\n",
        "            links.append(link)\n",
        "            count += 1\n",
        "            if(count > n_images):\n",
        "                break\n",
        "\n",
        "        except KeyError:\n",
        "            continue\n",
        "            \n",
        "    print(f\"Found {len(links)} images.\\n\")\n",
        "    print(f\"Downloading {len(links)} images...\\n\")\n",
        "\n",
        "    curr_path = pathlib.Path()\n",
        "    saved_folder = curr_path / 'images' / data\n",
        "\n",
        "    pathlib.Path(saved_folder).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    for i, link in enumerate(links):\n",
        "        response = requests.get(link)\n",
        "        filename = data + str(i+1) + '.jpg'\n",
        "        image_name = saved_folder / filename\n",
        "\n",
        "        with open(image_name, 'wb') as fh:\n",
        "            fh.write(response.content)\n",
        "    \n",
        "    print(f\"Finished downloading!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEjXaDtHAMjS",
        "outputId": "5ab23647-b080-49ec-e59a-e671c908684f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What are you looking for? cat\n",
            "How many images do you want? 95\n",
            "\n",
            "Searching for 95...\n",
            "\n",
            "Found 80 images.\n",
            "\n",
            "Downloading 80 images...\n",
            "\n",
            "Finished downloading!\n"
          ]
        }
      ],
      "source": [
        "download_images()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "path = pathlib.Path().cwd()\n",
        "print(path)\n",
        "images_path = path/\"images\"\n",
        "print(images_path) \n",
        "\n",
        "dict = {}\n",
        "\n",
        "for fldr in images_path.iterdir():\n",
        "  print(fldr.name)\n",
        "  dict[fldr.name] = []\n",
        "for img in fldr.iterdir():\n",
        "   dict[fldr.name].append(img)\n",
        "  \n",
        "dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0XTHpU8LsL5",
        "outputId": "d1190c63-640e-4c81-9f3f-06bd13f92fa6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content/images\n",
            "cat\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cat': [PosixPath('/content/images/cat/cat68.jpg'),\n",
              "  PosixPath('/content/images/cat/cat58.jpg'),\n",
              "  PosixPath('/content/images/cat/cat28.jpg'),\n",
              "  PosixPath('/content/images/cat/cat3.jpg'),\n",
              "  PosixPath('/content/images/cat/cat45.jpg'),\n",
              "  PosixPath('/content/images/cat/cat22.jpg'),\n",
              "  PosixPath('/content/images/cat/cat12.jpg'),\n",
              "  PosixPath('/content/images/cat/cat50.jpg'),\n",
              "  PosixPath('/content/images/cat/cat75.jpg'),\n",
              "  PosixPath('/content/images/cat/cat57.jpg'),\n",
              "  PosixPath('/content/images/cat/cat2.jpg'),\n",
              "  PosixPath('/content/images/cat/cat4.jpg'),\n",
              "  PosixPath('/content/images/cat/cat62.jpg'),\n",
              "  PosixPath('/content/images/cat/cat46.jpg'),\n",
              "  PosixPath('/content/images/cat/cat55.jpg'),\n",
              "  PosixPath('/content/images/cat/cat24.jpg'),\n",
              "  PosixPath('/content/images/cat/cat25.jpg'),\n",
              "  PosixPath('/content/images/cat/cat36.jpg'),\n",
              "  PosixPath('/content/images/cat/cat8.jpg'),\n",
              "  PosixPath('/content/images/cat/cat5.jpg'),\n",
              "  PosixPath('/content/images/cat/cat71.jpg'),\n",
              "  PosixPath('/content/images/cat/cat1.jpg'),\n",
              "  PosixPath('/content/images/cat/cat41.jpg'),\n",
              "  PosixPath('/content/images/cat/cat49.jpg'),\n",
              "  PosixPath('/content/images/cat/cat79.jpg'),\n",
              "  PosixPath('/content/images/cat/cat64.jpg'),\n",
              "  PosixPath('/content/images/cat/cat65.jpg'),\n",
              "  PosixPath('/content/images/cat/cat23.jpg'),\n",
              "  PosixPath('/content/images/cat/cat56.jpg'),\n",
              "  PosixPath('/content/images/cat/cat66.jpg'),\n",
              "  PosixPath('/content/images/cat/cat61.jpg'),\n",
              "  PosixPath('/content/images/cat/cat67.jpg'),\n",
              "  PosixPath('/content/images/cat/cat18.jpg'),\n",
              "  PosixPath('/content/images/cat/cat32.jpg'),\n",
              "  PosixPath('/content/images/cat/cat44.jpg'),\n",
              "  PosixPath('/content/images/cat/cat69.jpg'),\n",
              "  PosixPath('/content/images/cat/cat42.jpg'),\n",
              "  PosixPath('/content/images/cat/cat80.jpg'),\n",
              "  PosixPath('/content/images/cat/cat47.jpg'),\n",
              "  PosixPath('/content/images/cat/cat14.jpg'),\n",
              "  PosixPath('/content/images/cat/cat73.jpg'),\n",
              "  PosixPath('/content/images/cat/cat78.jpg'),\n",
              "  PosixPath('/content/images/cat/cat48.jpg'),\n",
              "  PosixPath('/content/images/cat/cat11.jpg'),\n",
              "  PosixPath('/content/images/cat/cat70.jpg'),\n",
              "  PosixPath('/content/images/cat/cat20.jpg'),\n",
              "  PosixPath('/content/images/cat/cat10.jpg'),\n",
              "  PosixPath('/content/images/cat/cat30.jpg'),\n",
              "  PosixPath('/content/images/cat/cat60.jpg'),\n",
              "  PosixPath('/content/images/cat/cat21.jpg'),\n",
              "  PosixPath('/content/images/cat/cat27.jpg'),\n",
              "  PosixPath('/content/images/cat/cat26.jpg'),\n",
              "  PosixPath('/content/images/cat/cat37.jpg'),\n",
              "  PosixPath('/content/images/cat/cat40.jpg'),\n",
              "  PosixPath('/content/images/cat/cat52.jpg'),\n",
              "  PosixPath('/content/images/cat/cat35.jpg'),\n",
              "  PosixPath('/content/images/cat/cat53.jpg'),\n",
              "  PosixPath('/content/images/cat/cat43.jpg'),\n",
              "  PosixPath('/content/images/cat/cat72.jpg'),\n",
              "  PosixPath('/content/images/cat/cat7.jpg'),\n",
              "  PosixPath('/content/images/cat/cat77.jpg'),\n",
              "  PosixPath('/content/images/cat/cat39.jpg'),\n",
              "  PosixPath('/content/images/cat/cat51.jpg'),\n",
              "  PosixPath('/content/images/cat/cat6.jpg'),\n",
              "  PosixPath('/content/images/cat/cat9.jpg'),\n",
              "  PosixPath('/content/images/cat/cat63.jpg'),\n",
              "  PosixPath('/content/images/cat/cat19.jpg'),\n",
              "  PosixPath('/content/images/cat/cat29.jpg'),\n",
              "  PosixPath('/content/images/cat/cat16.jpg'),\n",
              "  PosixPath('/content/images/cat/cat54.jpg'),\n",
              "  PosixPath('/content/images/cat/cat34.jpg'),\n",
              "  PosixPath('/content/images/cat/cat38.jpg'),\n",
              "  PosixPath('/content/images/cat/cat33.jpg'),\n",
              "  PosixPath('/content/images/cat/cat74.jpg'),\n",
              "  PosixPath('/content/images/cat/cat31.jpg'),\n",
              "  PosixPath('/content/images/cat/cat17.jpg'),\n",
              "  PosixPath('/content/images/cat/cat13.jpg'),\n",
              "  PosixPath('/content/images/cat/cat76.jpg'),\n",
              "  PosixPath('/content/images/cat/cat15.jpg'),\n",
              "  PosixPath('/content/images/cat/cat59.jpg')]}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict.keys()"
      ],
      "metadata": {
        "id": "Q1UC5mSrSCFL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44f60d04-6115-49f0-a33d-9c3e96bc22a3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['cat'])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array, smart_resize\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "sMbKjB91rOAW"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=[]\n",
        "for fldr in images_path.iterdir():\n",
        "  print(fldr.name)\n",
        "for img in fldr.iterdir():\n",
        "    img = load_img(img)\n",
        "    img_array = img_to_array(img)\n",
        "    img_array_resized = smart_resize(img_array, [224,224])\n",
        "    x_train.append(img_array_resized) \n",
        "\n",
        "        \n",
        "x_train=np.array(x_train)\n",
        "       \n"
      ],
      "metadata": {
        "id": "OpeR-UqzVMmA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f193c0eb-e7f1-49c0-ed73-35cb1c50c6e5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPD3_4fLzjo_",
        "outputId": "2f2d8f0e-bcf3-4d2f-cf4e-0ea684b9f6b2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80, 224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMDSxX5SAMjT"
      },
      "source": [
        "## Part 2: Using the Original Data\n",
        "\n",
        "### Dataset Verification\n",
        "\n",
        "You should verify that the training, validation, and test sets have the correct number of images (the `os` functions should help with this) and that the data is organized in `train`, `validation`, and `test` folders. \n",
        "\n",
        "### Dataset Loading and Processing with Image Data Generators\n",
        "\n",
        "You should now create image data generators for your training, validation, and test datasets that will allow you to feed them into your model in batches. The images should be resized to 180x180 pixels and scaled so all pixel values are between 0 and 1. \n",
        "\n",
        "### Create and Evaluate a Model\n",
        "\n",
        "Build a convolutional neural network and use the validation loss and accuracy to select the best architecture and hyperparameters so that you can maximize the validation accuracy. \n",
        "\n",
        "Any overfitting should be addressed; that is, if your model begins overfitting after epoch 3, you should not quote validation accuracy after epoch 15. And, appropriate attempts should be made to reduce/eliminate the overfitting to improve overall model generalizability. \n",
        "\n",
        "### Report Accuracy on Test Set \n",
        "\n",
        "Your final step is to make predictions using the test set and report the final test set accuracy. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qovArWInAMjU"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7k-zAhRAMjU"
      },
      "source": [
        "## Part 3: Using Data Augmentation\n",
        "\n",
        "### Dataset Loading and Processing with Create Image Data Generators\n",
        "\n",
        "You should now create image data generators for your training, validation, and test datasets that will allow you to feed them into your model in batches. The images should be resized to 148x148 pixels and scaled so all pixel values are between 0 and 1. \n",
        "\n",
        "### Add Data Augmentation \n",
        "\n",
        "You should now add data augmentation to your training data generator ONLY. All useful types of augmentation should be used. \n",
        "\n",
        "### Create and Evaluate a Baseline Model\n",
        "\n",
        "Use the best model from **Part 2** to train with the augmented data and evaluate on the validation data to get a baseline accuracy for the new model trained on the augmented dataset. \n",
        "\n",
        "### Tune the Model\n",
        "\n",
        "With a more complex training set, you may be able to improve the accuracy through adjustments to the baseline model architecture and tuning the hyperparameters. \n",
        "\n",
        "### Report Accuracy on Test Set \n",
        "\n",
        "Your final step is to make predictions using the test set and report the final test set accuracy. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dh8TADtXAMjV"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "Lab_4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}